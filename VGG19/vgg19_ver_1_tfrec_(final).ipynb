{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg19_ver_1_tfrec (final).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGvYY2zkiOVN"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"daxinniu122\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"2ed6804df3e3e2e0d5053c862fa7020a\" # key from the json file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb8S6JIlijb6",
        "outputId": "2460f801-e973-446d-e5e2-40f28d2a9306"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPJ6Z0RfunBu"
      },
      "source": [
        "import zipfile\n",
        "for i in os.listdir('/content/'):\n",
        "    if 'zip' in i:\n",
        "        with zipfile.ZipFile(i, 'r') as f:\n",
        "            f.extractall('/content/drive/MyDrive/cassava-leaf-disease-classification/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snpx7a8_jPLO",
        "outputId": "4117be18-48b4-4b9a-aa7d-9638db8be680"
      },
      "source": [
        "# Library import\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import albumentations as alb\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.applications import VGG19, ResNet152V2, InceptionResNetV2, ResNet50\n",
        "from tensorflow.keras.layers import AveragePooling2D, Activation, GlobalAveragePooling2D\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from functools import partial\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.applications import EfficientNetB3, EfficientNetB4\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from functools import partial\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Constant Variables:\n",
        "_auto_tune = tf.data.experimental.AUTOTUNE\n",
        "_batch_size = 32\n",
        "\n",
        "_image_width_original = 512\n",
        "_image_height_original = 512\n",
        "_image_size = [_image_width_original, _image_height_original]\n",
        "\n",
        "_image_resize_width = 336\n",
        "_image_resize_height = 336\n",
        "_image_resize = [_image_resize_width, _image_resize_height]\n",
        "print('Model input shape {} x {}.'.format(_image_resize_width, _image_resize_height))\n",
        "\n",
        "_channels = 3\n",
        "_n_class = 5\n",
        "_n_repeat = 4\n",
        "_img_norm = 255.0\n",
        "\n",
        "_classes = [str(x) for x in range(_n_class)]\n",
        "_major_label = 3\n",
        "_classes_names = ['Cassava Bacterial Blight',\n",
        "                  'Cassava Brown Streak Disease',\n",
        "                  'Cassava Green Mottle',\n",
        "                  'Cassava Mosaic Disease',\n",
        "                  'Healthy']\n",
        "_train_file = '/content/drive/MyDrive/cassava-leaf-disease-classification/'\n",
        "_train_recs = list(filter(lambda x: '.tfrec' in x, os.listdir(_train_file)))\n",
        "_epochs = 20\n",
        "_valid_size = 0.1\n",
        "_train_df = pd.read_csv('/content/drive/MyDrive/cassava-leaf-disease-classification/train.csv', encoding='utf_8_sig',\n",
        "                        engine='python')\n",
        "_file_label_map = dict(zip(_train_df.image_id.tolist(), _train_df.label.astype(int).tolist()))\n",
        "_random_corp_size = [_image_resize_width, _image_resize_height, _channels]\n",
        "\n",
        "\n",
        "# Decoding single image:\n",
        "def decode_img(img,\n",
        "               n_channels: int = _channels,\n",
        "               img_size: list = None,\n",
        "               img_norm: float = _img_norm):\n",
        "    if img_size is None:\n",
        "        img_size = _image_size\n",
        "    img = tf.image.decode_jpeg(img, channels=n_channels)\n",
        "    img = tf.reshape(img, [*img_size, n_channels])\n",
        "    return img\n",
        "\n",
        "\n",
        "# Parsing the files\n",
        "def parse_img(x,\n",
        "              n_class: int = _n_class):\n",
        "    feature_description = {'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
        "                           'target': tf.io.FixedLenFeature([], tf.int64, default_value=-1)}\n",
        "    parsed_features = tf.io.parse_single_example(x, feature_description)\n",
        "    img = decode_img(parsed_features['image'])\n",
        "    label = tf.one_hot(parsed_features['target'], depth=n_class)\n",
        "    return img, label\n",
        "\n",
        "\n",
        "# Load data\n",
        "def load_img(files: list,\n",
        "             ordered=False):\n",
        "    df = tf.data.TFRecordDataset(files)\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False\n",
        "    df = df.with_options(ignore_order)\n",
        "    df = df.map(parse_img)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Train-validation split\n",
        "_train_fn, _valid_fn = \\\n",
        "    train_test_split(tf.io.gfile.glob(_train_file + 'ld_train*.tfrec'),\n",
        "                     test_size=_valid_size,\n",
        "                     random_state=5,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model input shape 336 x 336.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXWaOKwkubHR",
        "outputId": "a92262b3-d62c-4b45-face-56b9258dd081"
      },
      "source": [
        "\n",
        "# Function for getting the training data set\n",
        "def get_train_data(train_fn: list = _train_fn,\n",
        "                   batch_size: int = _batch_size):\n",
        "    df = load_img(train_fn)\n",
        "    df = df.repeat().shuffle(2048).batch(batch_size).prefetch(_auto_tune)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Function for getting the validation data set\n",
        "def get_valid_data(valid_fn: list = _valid_fn,\n",
        "                   batch_size: int = _batch_size):\n",
        "    df = load_img(valid_fn)\n",
        "    df = df.batch(batch_size).cache().prefetch(_auto_tune)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Reporting the size of training, validation and testing data\n",
        "def report_data_size(train_f=_train_fn,\n",
        "                     valid_f=_valid_fn):\n",
        "    def count_file(x):\n",
        "        return sum([int(re.compile(r\"-([0-9]*)\\.\").search(i).group(1)) for i in x])\n",
        "\n",
        "    n_train, n_valid= count_file(train_f), count_file(valid_f)\n",
        "    print('Train Images: {} | Validation Images: {}'.format(n_train, n_valid))\n",
        "    return n_train, n_valid\n",
        "\n",
        "\n",
        "# Check the size of the data\n",
        "_n_train, _n_valid = report_data_size()\n",
        "\n",
        "# Fetching training, validation and testing data\n",
        "train_data = get_train_data()\n",
        "valid_data = get_valid_data()\n",
        "\n",
        "print(\"Train Data Size {} | Validation Data Size {}\".format(train_data._flat_shapes, valid_data._flat_shapes))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Images: 18721 | Validation Images: 2676\n",
            "Train Data Size [TensorShape([None, 512, 512, 3]), TensorShape([None, 5])] | Validation Data Size [TensorShape([None, 512, 512, 3]), TensorShape([None, 5])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXZrktqizGth"
      },
      "source": [
        "input_module = tf.keras.layers.Input(shape=(*_image_size, _channels))\n",
        "flip_module = tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal_and_vertical')\n",
        "roration_module = tf.keras.layers.experimental.preprocessing.RandomRotation(factor=(-0.4, 0.4))\n",
        "crop_module = tf.keras.layers.experimental.preprocessing.RandomCrop(height=_image_resize_height, width=_image_resize_width)\n",
        "rand_height_module = tf.keras.layers.experimental.preprocessing.RandomHeight(factor=0.25)\n",
        "rand_width_module = tf.keras.layers.experimental.preprocessing.RandomWidth(factor=0.25)\n",
        "contrast_module = tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.3)\n",
        "rescale_module = tf.keras.layers.experimental.preprocessing.Rescaling(scale=1/255)\n",
        "zoom_module = tf.keras.layers.experimental.preprocessing.RandomZoom(0.5, 0.3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82OCc4VH000t"
      },
      "source": [
        "def load_model():\n",
        "    base = VGG19(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(None, None, 3))\n",
        "\n",
        "    x = base.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(5,\n",
        "              activation='softmax')(x)\n",
        "    m = Model(inputs=base.input, outputs=x)\n",
        "    return m"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4-7Cfmh4gG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76974533-dd81-4010-974f-1add1002a155"
      },
      "source": [
        "_opt = tf.keras.optimizers.Adam(lr=1e-05)\n",
        "_loss = CategoricalCrossentropy(label_smoothing=0.05)\n",
        "_epochs = 20\n",
        "_finetune_epochs = 10\n",
        "\n",
        "model_ver_4 = load_model()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do7hpEpkJinf"
      },
      "source": [
        "model = tf.keras.Sequential([input_module, \n",
        "                             flip_module,\n",
        "                             roration_module,\n",
        "                             crop_module,\n",
        "                             rand_height_module,\n",
        "                             rand_width_module,\n",
        "                             contrast_module,\n",
        "                             zoom_module,\n",
        "                             rescale_module,\n",
        "                             model_ver_4])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObeC4aC86uad"
      },
      "source": [
        "model.compile(\n",
        "        optimizer=_opt,\n",
        "        loss=_loss,\n",
        "        metrics=['accuracy']\n",
        "    )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkfI0sZV5bYA",
        "outputId": "0e604ef2-dbc6-439c-d0ba-543080e3c543"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "random_flip (RandomFlip)     (None, 512, 512, 3)       0         \n",
            "_________________________________________________________________\n",
            "random_rotation (RandomRotat (None, 512, 512, 3)       0         \n",
            "_________________________________________________________________\n",
            "random_crop (RandomCrop)     (None, 336, 336, 3)       0         \n",
            "_________________________________________________________________\n",
            "random_height (RandomHeight) (None, None, 336, 3)      0         \n",
            "_________________________________________________________________\n",
            "random_width (RandomWidth)   (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "random_contrast (RandomContr (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "random_zoom (RandomZoom)     (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "rescaling (Rescaling)        (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "model (Functional)           (None, 5)                 20026949  \n",
            "=================================================================\n",
            "Total params: 20,026,949\n",
            "Trainable params: 20,026,949\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsA1ysKT5fV2",
        "outputId": "3717d835-a244-4425-a345-9db14bf85b58"
      },
      "source": [
        "import pickle\n",
        "_es = EarlyStopping(monitor='val_loss',\n",
        "                    mode='min',\n",
        "                    patience=10)\n",
        "_r = ReduceLROnPlateau(monitor='val_loss',\n",
        "                       factor=0.8,\n",
        "                       patience=2,\n",
        "                       verbose=1,\n",
        "                       mode='auto',\n",
        "                       epsilon=0.0001,\n",
        "                       cooldown=5,\n",
        "                       min_lr=0.00001)\n",
        "\n",
        "_callback = [_es, _r]\n",
        "\n",
        "history = model.fit(train_data, validation_data=valid_data, epochs=_epochs, callbacks=_callback, steps_per_epoch=_n_train//_batch_size)\n",
        "model.save('/content/drive/MyDrive/cassava-leaf-disease-classification/VGG19_ver_1.h5')\n",
        "with open('/content/drive/MyDrive/cassava-leaf-disease-classification/VGG19_ver_1.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "Epoch 1/20\n",
            "585/585 [==============================] - 2656s 4s/step - loss: 1.0503 - accuracy: 0.6423 - val_loss: 0.7782 - val_accuracy: 0.7657\n",
            "Epoch 2/20\n",
            "585/585 [==============================] - 2010s 3s/step - loss: 0.7726 - accuracy: 0.7622 - val_loss: 0.7166 - val_accuracy: 0.7997\n",
            "Epoch 3/20\n",
            "585/585 [==============================] - 1726s 3s/step - loss: 0.7056 - accuracy: 0.8000 - val_loss: 0.6413 - val_accuracy: 0.8281\n",
            "Epoch 4/20\n",
            "585/585 [==============================] - 1502s 3s/step - loss: 0.6872 - accuracy: 0.8041 - val_loss: 0.6367 - val_accuracy: 0.8330\n",
            "Epoch 5/20\n",
            "585/585 [==============================] - 1436s 2s/step - loss: 0.6659 - accuracy: 0.8133 - val_loss: 0.6036 - val_accuracy: 0.8460\n",
            "Epoch 6/20\n",
            "585/585 [==============================] - 1271s 2s/step - loss: 0.6431 - accuracy: 0.8256 - val_loss: 0.6004 - val_accuracy: 0.8501\n",
            "Epoch 7/20\n",
            "585/585 [==============================] - 1176s 2s/step - loss: 0.6393 - accuracy: 0.8273 - val_loss: 0.6149 - val_accuracy: 0.8460\n",
            "Epoch 8/20\n",
            "585/585 [==============================] - 1070s 2s/step - loss: 0.6295 - accuracy: 0.8311 - val_loss: 0.5924 - val_accuracy: 0.8464\n",
            "Epoch 9/20\n",
            "585/585 [==============================] - 1052s 2s/step - loss: 0.6171 - accuracy: 0.8402 - val_loss: 0.5934 - val_accuracy: 0.8472\n",
            "Epoch 10/20\n",
            "585/585 [==============================] - 1005s 2s/step - loss: 0.6155 - accuracy: 0.8377 - val_loss: 0.6141 - val_accuracy: 0.8472\n",
            "Epoch 11/20\n",
            "585/585 [==============================] - 906s 2s/step - loss: 0.6090 - accuracy: 0.8404 - val_loss: 0.5880 - val_accuracy: 0.8516\n",
            "Epoch 12/20\n",
            "585/585 [==============================] - 926s 2s/step - loss: 0.5985 - accuracy: 0.8449 - val_loss: 0.5570 - val_accuracy: 0.8662\n",
            "Epoch 13/20\n",
            "585/585 [==============================] - 881s 2s/step - loss: 0.6045 - accuracy: 0.8439 - val_loss: 0.5800 - val_accuracy: 0.8561\n",
            "Epoch 14/20\n",
            "585/585 [==============================] - 858s 1s/step - loss: 0.5868 - accuracy: 0.8460 - val_loss: 0.5744 - val_accuracy: 0.8558\n",
            "Epoch 15/20\n",
            "585/585 [==============================] - 801s 1s/step - loss: 0.5890 - accuracy: 0.8483 - val_loss: 0.6034 - val_accuracy: 0.8479\n",
            "Epoch 16/20\n",
            "585/585 [==============================] - 789s 1s/step - loss: 0.5865 - accuracy: 0.8510 - val_loss: 0.5791 - val_accuracy: 0.8602\n",
            "Epoch 17/20\n",
            "585/585 [==============================] - 751s 1s/step - loss: 0.5825 - accuracy: 0.8532 - val_loss: 0.5601 - val_accuracy: 0.8621\n",
            "Epoch 18/20\n",
            "585/585 [==============================] - 743s 1s/step - loss: 0.5688 - accuracy: 0.8564 - val_loss: 0.6111 - val_accuracy: 0.8457\n",
            "Epoch 19/20\n",
            "585/585 [==============================] - 712s 1s/step - loss: 0.5670 - accuracy: 0.8574 - val_loss: 0.5687 - val_accuracy: 0.8584\n",
            "Epoch 20/20\n",
            "585/585 [==============================] - 692s 1s/step - loss: 0.5720 - accuracy: 0.8565 - val_loss: 0.5570 - val_accuracy: 0.8677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osMaITAeW7xA",
        "outputId": "66b14e66-91eb-4b97-f56c-398d5f6d8daf"
      },
      "source": [
        "for i in model_ver_4.layers:\n",
        "    i.trainable = True\n",
        "    if 'bn' in i.name:\n",
        "        i.trainable = False\n",
        "history2 = model.fit(train_data, validation_data=valid_data, epochs=10, callbacks=_callback, steps_per_epoch=_n_train//_batch_size)\n",
        "model.save('/content/drive/MyDrive/cassava-leaf-disease-classification/VGG19_ver_1_cp2.h5')\n",
        "with open('/content/drive/MyDrive/cassava-leaf-disease-classification/VGG19_ver_1_cp2.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "585/585 [==============================] - 678s 1s/step - loss: 0.5681 - accuracy: 0.8572 - val_loss: 0.5676 - val_accuracy: 0.8580\n",
            "Epoch 2/10\n",
            "585/585 [==============================] - 669s 1s/step - loss: 0.5670 - accuracy: 0.8584 - val_loss: 0.5655 - val_accuracy: 0.8610\n",
            "Epoch 3/10\n",
            "585/585 [==============================] - 602s 1s/step - loss: 0.5593 - accuracy: 0.8624 - val_loss: 0.5548 - val_accuracy: 0.8655\n",
            "Epoch 4/10\n",
            "585/585 [==============================] - 632s 1s/step - loss: 0.5610 - accuracy: 0.8593 - val_loss: 0.5389 - val_accuracy: 0.8670\n",
            "Epoch 5/10\n",
            "585/585 [==============================] - 607s 1s/step - loss: 0.5576 - accuracy: 0.8612 - val_loss: 0.5854 - val_accuracy: 0.8524\n",
            "Epoch 6/10\n",
            "585/585 [==============================] - 604s 1s/step - loss: 0.5558 - accuracy: 0.8631 - val_loss: 0.5456 - val_accuracy: 0.8722\n",
            "Epoch 7/10\n",
            "585/585 [==============================] - 571s 977ms/step - loss: 0.5499 - accuracy: 0.8641 - val_loss: 0.5417 - val_accuracy: 0.8711\n",
            "Epoch 8/10\n",
            "585/585 [==============================] - 566s 967ms/step - loss: 0.5492 - accuracy: 0.8660 - val_loss: 0.5515 - val_accuracy: 0.8670\n",
            "Epoch 9/10\n",
            "585/585 [==============================] - 572s 978ms/step - loss: 0.5543 - accuracy: 0.8630 - val_loss: 0.5656 - val_accuracy: 0.8606\n",
            "Epoch 10/10\n",
            "585/585 [==============================] - 540s 924ms/step - loss: 0.5499 - accuracy: 0.8665 - val_loss: 0.5538 - val_accuracy: 0.8670\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}